---
layout: post
title: ST558 - Project 2 Blog Post
---

<b>Link to Project 2 repository:</b>   <a href="https://ztvaskal.github.io/ST558Project2/">https://ztvaskal.github.io/ST558Project2/</a>

<i><b>What would I do differently?</b></i>    
These projects are challenging!  Not to mention we have the normal class homework and studying to do, but once again I am stumped on what I could be doing differently.  Part of it is the sheer number of classes I am taking this summer, which all have substantial amounts of work.  But, that being said I think I am happy how this project turned out.  I suppose we will see.  One thing I will say is that the automated markdown component to this project was the hardest piece.  I don't think I understand how apply() or pwalk() are passing the parameters.  I know R Studio has that trace feature to trace back an error, but what I would like to learn how to do (and I'm sure you can) is to look at the data buffer and see what values are stored in the variables when the process breaks.  Or even if the process runs, is there a way we could see what the last value the apply function had for params?  I think that would have been helpful here.

<i><b>What was the most difficult part for me?</b></i>  
The most difficult aspect, in my opinion, again was the automation component.  Dr. Post, your lecture was great, the code was short and sweet and I feel like I adapted it easily, but then getting it to actually do the right thing was not a trivial task.  I used your lecture notes to complete the project, and I happy knowing that each of the analysis files is correct, but I know this part should have been easier than I found it.  Totally my fault though, I just still don't know enough about R.  As I mentioned above, I think personally for me, it would be beneficial to know how to access values in the memory buffer, to trace back through function calls.  It's difficult too, because all of the functions in R are so dynamic there are multiple layers to each of the functions.  Also, in writing programs like this, I think part of the struggle I was having was having old values still stored in the variable, and the code was running but using the old values instead.  Still trying to process through some of it!

<i><b>What are your big take-aways from this project?</b></i>  
My big take-aways for this project are that I have learned so much but still know so little.  I am certainly getting more comfortable in R, and I am really enjoying this class.  I am actually very happy with how all of my courses are going this summer, considering the load.  Between this and SAS it is quite a substantial amount of programming, but it works out really well because we are using both R and SAS in the ST 512 class, so that's been really helpful.  Sorry I got off topic for a second there, but I just wanted you to know that I really appreciate this class and everything you are teaching us - and really for taking up 10 weeks of your summer to do it, I really appreciate it.  

Other take-aways from this project are that I love being able to produce similar reports with one R Markdown file.  I have to think about how I can integrate that into my job at the medical school.  There are certain tasks I think this could lend itself well to.  Also, I am a really big fan of all the non-linear methods you taught us in Module 10.  I don't know if it is dissertation worthy, probably not, but in any case it might be an interesting project on prediction and I believe would work well with some of these tree-based methods.  We can chat about it sometime maybe if you wouldn't mind.  The gist of it would be either predicting student medical board licensure scores based on a variety of performance indicators, or simply predicting pass-fail status on the boards.  Most articles in the literature do some sort of multiple regression, which makes sense, but I think the kNN, bagged, boosted, and random forest methods might be more interesting and actually yield better results.  I've been pondering it for a while and it would be nice to see something come of it, especially if the model ended up being very accurate.  In any case, thank you again Dr. Post for another challenging assignment!  It was fun, but I am glad there is only one more project to go! :)
